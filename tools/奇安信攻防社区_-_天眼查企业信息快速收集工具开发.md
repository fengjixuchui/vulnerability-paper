<meta name="referrer" content="no-referrer"/>
> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 [forum.butian.net](https://forum.butian.net/share/1022)

> 奇安信攻防社区 - 天眼查企业信息快速收集工具开发

集团最近需要收集到各大子公司在公网上比如网盘啊, github 上泄露的一些数据, 貌似每年年底都会有这活, 所以第一步就需要获取一大堆子公司的域名啥的, 由于数据过多, 想着不可能一个一个上天眼查上找, 所以花了一晚上写了一个小工具, 好像记得网上是有一个企查查相关的查询工具的, 但是秉着提升自己的原则, 还是打算自己写一个, 于是便有了下文的代码, 我将给大家分析下我写的一些思路, 希望对大家有所帮助。

```
#author:soufaker
```

具体使用方法也很简单:

在配置文件中写入 COOKIE 信息, 如果只是爬取公司单页数据, 无需 cookie,cookie 抓取按如下操作:

1. 登陆天眼查后, 随意查询一个公司, 在在该公司的股权图中, 在点击除第一页页码外的页码抓取包中, 获取 cookie, 直接复制到 cookie.ini 中即可。  
![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-630c3ef0c94040bef605e561ea60009110cf9cab.png)

2. 使用抓包软件将 cookie 抓取直接放入 cookie.ini 中：

![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-2dced27087d3fb1fc8d5038a0a4ca6f32b80ce66.png)  
![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-757d592332a61da238fa2ccc5a947753db2b7bc4.png)

3. 使用如下命令即可开跑:

python3 Tyz_Get_Info.py -o(可填可不填) 数值 -r test.txt

python3 Tyz_Get_Info.py -o(可填可不填) 数值 -c “公司名或网址”

### 查询所需爬虫接口

第一步我们需要通过抓包来获取到想要查询数据的接口, 有的也可以通过网站网址 url, 下面给大家列举本次需要用到的几个接口:

1.[https://www.tianyancha.com/search?key](https://www.tianyancha.com/search?key)=’’ (通过首页的天眼一下, 输入我们想要查询公司的名字或者网址都行, 会定位到以下页面, 当然我打了码)  
![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-ef4bc38beb95cf8686977db78dff4dc7951e070a.jpg)

2. 点击下面排序公司的第一个公司, 一般都是总公司, 只要你输入的公司全称够详细, 然后我们点进这个公司会调用以下接口:

[https://www.tianyancha.com/company/+id(该 ID 为标识公司的唯一数字 ID, 可以通过我们上边返回页面进行爬取](https://www.tianyancha.com/company/+id(%E8%AF%A5ID%E4%B8%BA%E6%A0%87%E8%AF%86%E5%85%AC%E5%8F%B8%E7%9A%84%E5%94%AF%E4%B8%80%E6%95%B0%E5%AD%97ID,%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E6%88%91%E4%BB%AC%E4%B8%8A%E8%BE%B9%E8%BF%94%E5%9B%9E%E9%A1%B5%E9%9D%A2%E8%BF%9B%E8%A1%8C%E7%88%AC%E5%8F%96))

![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-c0f645db87264678b33a02630df3da16e58cfbc7.jpg)

3. 如果该公司够大, 点进该页面就会有他的股权架构图, 大家平时用应该也知道, 然后他下面有个股权列表, 列表中包含子公司的名字, 股权占用率, 是否存续啥的, 我们需要获取这些信息去爬取这些子公司的信息, 当然子公司的下面还可能有子公司, 这里下面会讲到如何一直循环往下爬取, 该表如果数据过多会存在分页, 这里分页的数据需要有 cookie 才行, 所以代码中添加了 cookie 参数的设置, 如果只查询一页到没必要哈, 然后我们需要抓取分页的接口, 这里用 bp, 点击任意一页抓包获取到接口如下:

[https://www.tianyancha.com/pagination/investV2.xhtml?ps=20(单页显示的数量)&pn=3(页码)&id=xx(公司唯一 ID](https://www.tianyancha.com/pagination/investV2.xhtml?ps=20(%E5%8D%95%E9%A1%B5%E6%98%BE%E7%A4%BA%E7%9A%84%E6%95%B0%E9%87%8F)&pn=3(%E9%A1%B5%E7%A0%81)&id=xx(%E5%85%AC%E5%8F%B8%E5%94%AF%E4%B8%80ID))

![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-58fe42f395d2d9ce13439c859b5f3b56c3057469.jpg)

### 根据接口返回信息, 提取关键信息

通过上一步已经分析出需要哪些接口了, 这一步就需要通过查询到的返回信息, 进行提取我们想到要的数据了.

#### 1. 理清爬取方式

这里使我比较常用的 2 种方式:

1.xpath 路径爬取 (本工具就一处使用, 考虑到该路径唯一不变化好使用）

![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-b326f537c71bbbc25525e5acc53b11cd41690ffb.jpg)

```
#time:2021/12/14
```

2. 将网页返回的文本数据去掉所有特殊符号变为一段文本, 根据特征进行提取关键信息 (这个我比较喜欢用) 用到的主要提取代码如下:

```
import requests
```

主要用到的原理就是找到我们想要获取字符的前后位置是否存在能确定该字符的字符, 然后找到该特殊字符的前后字符的索引, 利用切片即可获取数据, 就比如我们爬虫第一步是获取主公司的唯一 ID，在第一步添加 key 后参数获取到的页面里它的 ID 在字符 [https://www.tianyancha.com/company / 和 target=\_blank > 之中, 我们就提取它的这 2 个字符的索引然后提取就行了, 其他地方也是如此。](https://www.tianyancha.com/company/%E5%92%8Ctarget=/_blank%3E%E4%B9%8B%E4%B8%AD,%E6%88%91%E4%BB%AC%E5%B0%B1%E6%8F%90%E5%8F%96%E5%AE%83%E7%9A%84%E8%BF%992%E4%B8%AA%E5%AD%97%E7%AC%A6%E7%9A%84%E7%B4%A2%E5%BC%95%E7%84%B6%E5%90%8E%E6%8F%90%E5%8F%96%E5%B0%B1%E8%A1%8C%E4%BA%86,%E5%85%B6%E4%BB%96%E5%9C%B0%E6%96%B9%E4%B9%9F%E6%98%AF%E5%A6%82%E6%AD%A4%E3%80%82)  
![](https://shs3.b.qianxin.com/attack_forum/2021/12/attach-6f62c6a887cd95c5aec7350c71ecf2102cdf8573.jpg)

2. 理清爬取顺序

这边根据我自己的代码可以理出一个顺序如下:

1. 查询总公司 ID———————-》2. 查询股权架构列表公司数量———————-》3. 查询分公司 ID（依次向下查询子公司 ID）汇总 ID———————-》4. 根据 ID 查询页面返回信息如 (公司名字, 邮箱, 电话)———————-》5. 存入表格, 文本

对应函数如下:

1.Get_Company_Id(company_name,company_name_list)——-》2.Get_Page_Num(company_id),get_all_page_id(num)——-》3.Get_ALL_Sub_Cmpany_Domain(company_id)，4.Get_Sub_Company_Domain——-》5.Write_To_Excel(company_info_list),Write_To_Txt(company_url_list)

1. 想要递归查询子公司的子公司数据, 可以利用 while 循环, 利用列表的 pop 方法, 每次 pop 一个数据出来, 如果爬取到子公司还有数据就往列表中添加, 直到列表中没有数据就退出 while 循环, 本次利用的代码如下:

```
import optparse
```

2. 对返回数据为列表的提取, 本次对股权架构列表进行以 % 分隔它们的字符，然后对每一个分隔出的字符再利用数据提取, 但对它是否注销还是存续的字符再 % 字符后, 也就是想要判断每一个子公司是否存续时是要根据原数据的索引去寻找, 只要依次增加索引位置就好了, 代码在获取分页所有子公司的 ID 处有用到, 如下:

```
from urllib.parse import quote,unquote
```